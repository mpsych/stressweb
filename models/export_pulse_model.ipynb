{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3968c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06badabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from physnet import PhysNet, SelfAttention, PulseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa98ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df12f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 32 \n",
    "model = PhysNet(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddde97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9137942",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "checkpoint = torch.load('pulsedetection.tar', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d5526c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): PhysNet(\n",
       "    (ConvBlock1): Sequential(\n",
       "      (0): Conv3d(3, 16, kernel_size=(1, 5, 5), stride=(1, 1, 1), padding=(0, 2, 2))\n",
       "      (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (ConvBlock2): Sequential(\n",
       "      (0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (ConvBlock3): Sequential(\n",
       "      (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (ConvBlock4): Sequential(\n",
       "      (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (ConvBlock5): Sequential(\n",
       "      (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (ConvBlock6): Sequential(\n",
       "      (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (ConvBlock7): Sequential(\n",
       "      (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (ConvBlock8): Sequential(\n",
       "      (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (ConvBlock9): Sequential(\n",
       "      (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (upsample): Sequential(\n",
       "      (0): ConvTranspose3d(64, 64, kernel_size=(4, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "    )\n",
       "    (upsample2): Sequential(\n",
       "      (0): ConvTranspose3d(64, 64, kernel_size=(4, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "    )\n",
       "    (ConvBlock10): Conv3d(64, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (MaxpoolSpa): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (MaxpoolSpaTem): MaxPool3d(kernel_size=(2, 2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (poolspa): AdaptiveAvgPool3d(output_size=(32, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee81cb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/onnx/utils.py:439: UserWarning: It is recommended that constant folding be turned off ('do_constant_folding=False') when exporting the model in training-amenable mode, i.e. with 'training=TrainingMode.TRAIN' or 'training=TrainingMode.PRESERVE' (when model is in training mode). Otherwise, some learnable model parameters may not translate correctly in the exported ONNX model because constant folding mutates model parameters. Please consider turning off constant folding or setting the training=TrainingMode.EVAL.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input.1 : Float(1, 3, 32, 120, 120, strides=[1382400, 460800, 14400, 120, 1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock1.0.weight : Float(16, 3, 1, 5, 5, strides=[75, 25, 25, 5, 1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock1.0.bias : Float(16, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock1.1.weight : Float(16, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock1.1.bias : Float(16, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock1.1.running_mean : Float(16, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock1.1.running_var : Float(16, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock2.0.weight : Float(32, 16, 3, 3, 3, strides=[432, 27, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock2.0.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock2.1.weight : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock2.1.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock2.1.running_mean : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock2.1.running_var : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock3.0.weight : Float(64, 32, 3, 3, 3, strides=[864, 27, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock3.0.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock3.1.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock3.1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock3.1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock3.1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock4.0.weight : Float(64, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock4.0.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock4.1.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock4.1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock4.1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock4.1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock5.0.weight : Float(64, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock5.0.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock5.1.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock5.1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock5.1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock5.1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock6.0.weight : Float(64, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock6.0.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock6.1.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock6.1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock6.1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock6.1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock7.0.weight : Float(64, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock7.0.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock7.1.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock7.1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock7.1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock7.1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock8.0.weight : Float(64, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock8.0.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock8.1.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock8.1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock8.1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock8.1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock9.0.weight : Float(64, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock9.0.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock9.1.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock9.1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock9.1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock9.1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %upsample.0.weight : Float(64, 64, 4, 1, 1, strides=[256, 4, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %upsample.0.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %upsample.1.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %upsample.1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %upsample.1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %upsample.1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %upsample2.0.weight : Float(64, 64, 4, 1, 1, strides=[256, 4, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %upsample2.0.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %upsample2.1.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %upsample2.1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %upsample2.1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %upsample2.1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %ConvBlock10.weight : Float(1, 64, 1, 1, 1, strides=[64, 1, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %ConvBlock10.bias : Float(1, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %onnx::Reshape_134 : Long(2, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %input : Float(1, 16, 32, 120, 120, strides=[7372800, 460800, 14400, 120, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[1, 5, 5], pads=[0, 2, 2, 0, 2, 2], strides=[1, 1, 1], onnx_name=\"Conv_0\"](%input.1, %ConvBlock1.0.weight, %ConvBlock1.0.bias) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/modules/conv.py:602:0\n",
      "  %input.4 : Float(1, 16, 32, 120, 120, strides=[7372800, 460800, 14400, 120, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002, onnx_name=\"BatchNormalization_1\"](%input, %ConvBlock1.1.weight, %ConvBlock1.1.bias, %ConvBlock1.1.running_mean, %ConvBlock1.1.running_var) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:2438:0\n",
      "  %onnx::MaxPool_83 : Float(1, 16, 32, 120, 120, strides=[7372800, 460800, 14400, 120, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"Relu_2\"](%input.4) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %input.8 : Float(1, 16, 32, 60, 60, strides=[1843200, 115200, 3600, 60, 1], requires_grad=1, device=cuda:0) = onnx::MaxPool[kernel_shape=[1, 2, 2], pads=[0, 0, 0, 0, 0, 0], strides=[1, 2, 2], onnx_name=\"MaxPool_3\"](%onnx::MaxPool_83) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:868:0\n",
      "  %input.12 : Float(1, 32, 32, 60, 60, strides=[3686400, 115200, 3600, 60, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1], onnx_name=\"Conv_4\"](%input.8, %ConvBlock2.0.weight, %ConvBlock2.0.bias) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/modules/conv.py:602:0\n",
      "  %input.16 : Float(1, 32, 32, 60, 60, strides=[3686400, 115200, 3600, 60, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002, onnx_name=\"BatchNormalization_5\"](%input.12, %ConvBlock2.1.weight, %ConvBlock2.1.bias, %ConvBlock2.1.running_mean, %ConvBlock2.1.running_var) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:2438:0\n",
      "  %onnx::Conv_87 : Float(1, 32, 32, 60, 60, strides=[3686400, 115200, 3600, 60, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"Relu_6\"](%input.16) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %input.20 : Float(1, 64, 32, 60, 60, strides=[7372800, 115200, 3600, 60, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1], onnx_name=\"Conv_7\"](%onnx::Conv_87, %ConvBlock3.0.weight, %ConvBlock3.0.bias) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/modules/conv.py:602:0\n",
      "  %input.24 : Float(1, 64, 32, 60, 60, strides=[7372800, 115200, 3600, 60, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002, onnx_name=\"BatchNormalization_8\"](%input.20, %ConvBlock3.1.weight, %ConvBlock3.1.bias, %ConvBlock3.1.running_mean, %ConvBlock3.1.running_var) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:2438:0\n",
      "  %onnx::MaxPool_90 : Float(1, 64, 32, 60, 60, strides=[7372800, 115200, 3600, 60, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"Relu_9\"](%input.24) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %input.28 : Float(1, 64, 16, 30, 30, strides=[921600, 14400, 900, 30, 1], requires_grad=1, device=cuda:0) = onnx::MaxPool[kernel_shape=[2, 2, 2], pads=[0, 0, 0, 0, 0, 0], strides=[2, 2, 2], onnx_name=\"MaxPool_10\"](%onnx::MaxPool_90) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:868:0\n",
      "  %input.32 : Float(1, 64, 16, 30, 30, strides=[921600, 14400, 900, 30, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1], onnx_name=\"Conv_11\"](%input.28, %ConvBlock4.0.weight, %ConvBlock4.0.bias) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/modules/conv.py:602:0\n",
      "  %input.36 : Float(1, 64, 16, 30, 30, strides=[921600, 14400, 900, 30, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002, onnx_name=\"BatchNormalization_12\"](%input.32, %ConvBlock4.1.weight, %ConvBlock4.1.bias, %ConvBlock4.1.running_mean, %ConvBlock4.1.running_var) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:2438:0\n",
      "  %onnx::Conv_94 : Float(1, 64, 16, 30, 30, strides=[921600, 14400, 900, 30, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"Relu_13\"](%input.36) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %input.40 : Float(1, 64, 16, 30, 30, strides=[921600, 14400, 900, 30, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1], onnx_name=\"Conv_14\"](%onnx::Conv_94, %ConvBlock5.0.weight, %ConvBlock5.0.bias) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/modules/conv.py:602:0\n",
      "  %input.44 : Float(1, 64, 16, 30, 30, strides=[921600, 14400, 900, 30, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002, onnx_name=\"BatchNormalization_15\"](%input.40, %ConvBlock5.1.weight, %ConvBlock5.1.bias, %ConvBlock5.1.running_mean, %ConvBlock5.1.running_var) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:2438:0\n",
      "  %onnx::MaxPool_97 : Float(1, 64, 16, 30, 30, strides=[921600, 14400, 900, 30, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"Relu_16\"](%input.44) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %input.48 : Float(1, 64, 8, 15, 15, strides=[115200, 1800, 225, 15, 1], requires_grad=1, device=cuda:0) = onnx::MaxPool[kernel_shape=[2, 2, 2], pads=[0, 0, 0, 0, 0, 0], strides=[2, 2, 2], onnx_name=\"MaxPool_17\"](%onnx::MaxPool_97) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:868:0\n",
      "  %input.52 : Float(1, 64, 8, 15, 15, strides=[115200, 1800, 225, 15, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1], onnx_name=\"Conv_18\"](%input.48, %ConvBlock6.0.weight, %ConvBlock6.0.bias) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/modules/conv.py:602:0\n",
      "  %input.56 : Float(1, 64, 8, 15, 15, strides=[115200, 1800, 225, 15, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002, onnx_name=\"BatchNormalization_19\"](%input.52, %ConvBlock6.1.weight, %ConvBlock6.1.bias, %ConvBlock6.1.running_mean, %ConvBlock6.1.running_var) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:2438:0\n",
      "  %onnx::Conv_101 : Float(1, 64, 8, 15, 15, strides=[115200, 1800, 225, 15, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"Relu_20\"](%input.56) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %input.60 : Float(1, 64, 8, 15, 15, strides=[115200, 1800, 225, 15, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1], onnx_name=\"Conv_21\"](%onnx::Conv_101, %ConvBlock7.0.weight, %ConvBlock7.0.bias) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/modules/conv.py:602:0\n",
      "  %input.64 : Float(1, 64, 8, 15, 15, strides=[115200, 1800, 225, 15, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002, onnx_name=\"BatchNormalization_22\"](%input.60, %ConvBlock7.1.weight, %ConvBlock7.1.bias, %ConvBlock7.1.running_mean, %ConvBlock7.1.running_var) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:2438:0\n",
      "  %onnx::MaxPool_104 : Float(1, 64, 8, 15, 15, strides=[115200, 1800, 225, 15, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"Relu_23\"](%input.64) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %x : Float(1, 64, 8, 7, 7, strides=[25088, 392, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::MaxPool[kernel_shape=[1, 2, 2], pads=[0, 0, 0, 0, 0, 0], strides=[1, 2, 2], onnx_name=\"MaxPool_24\"](%onnx::MaxPool_104) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:868:0\n",
      "  %input.68 : Float(1, 64, 8, 7, 7, strides=[25088, 392, 49, 7, 1], requires_grad=1, device=cuda:0), %107 : Tensor = onnx::Dropout[ratio=0.20000000000000001, onnx_name=\"Dropout_25\"](%x) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1252:0\n",
      "  %input.72 : Float(1, 64, 8, 7, 7, strides=[25088, 392, 49, 7, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1], onnx_name=\"Conv_26\"](%input.68, %ConvBlock8.0.weight, %ConvBlock8.0.bias) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/modules/conv.py:602:0\n",
      "  %input.76 : Float(1, 64, 8, 7, 7, strides=[25088, 392, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002, onnx_name=\"BatchNormalization_27\"](%input.72, %ConvBlock8.1.weight, %ConvBlock8.1.bias, %ConvBlock8.1.running_mean, %ConvBlock8.1.running_var) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:2438:0\n",
      "  %onnx::Dropout_110 : Float(1, 64, 8, 7, 7, strides=[25088, 392, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"Relu_28\"](%input.76) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %input.80 : Float(1, 64, 8, 7, 7, strides=[25088, 392, 49, 7, 1], requires_grad=1, device=cuda:0), %112 : Tensor = onnx::Dropout[ratio=0.20000000000000001, onnx_name=\"Dropout_29\"](%onnx::Dropout_110) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1252:0\n",
      "  %input.84 : Float(1, 64, 8, 7, 7, strides=[25088, 392, 49, 7, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1], onnx_name=\"Conv_30\"](%input.80, %ConvBlock9.0.weight, %ConvBlock9.0.bias) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/modules/conv.py:602:0\n",
      "  %input.88 : Float(1, 64, 8, 7, 7, strides=[25088, 392, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002, onnx_name=\"BatchNormalization_31\"](%input.84, %ConvBlock9.1.weight, %ConvBlock9.1.bias, %ConvBlock9.1.running_mean, %ConvBlock9.1.running_var) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:2438:0\n",
      "  %onnx::ConvTranspose_115 : Float(1, 64, 8, 7, 7, strides=[25088, 392, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"Relu_32\"](%input.88) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %input.92 : Float(1, 64, 16, 7, 7, strides=[50176, 784, 49, 7, 1], requires_grad=0, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1, 1], group=1, kernel_shape=[4, 1, 1], pads=[1, 0, 0, 1, 0, 0], strides=[2, 1, 1], onnx_name=\"ConvTranspose_33\"](%onnx::ConvTranspose_115, %upsample.0.weight, %upsample.0.bias) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/modules/conv.py:1102:0\n",
      "  %input.96 : Float(1, 64, 16, 7, 7, strides=[50176, 784, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002, onnx_name=\"BatchNormalization_34\"](%input.92, %upsample.1.weight, %upsample.1.bias, %upsample.1.running_mean, %upsample.1.running_var) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:2438:0\n",
      "  %onnx::ConvTranspose_118 : Float(1, 64, 16, 7, 7, strides=[50176, 784, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Elu[alpha=1., onnx_name=\"Elu_35\"](%input.96) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1549:0\n",
      "  %input.100 : Float(1, 64, 32, 7, 7, strides=[100352, 1568, 49, 7, 1], requires_grad=0, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1, 1], group=1, kernel_shape=[4, 1, 1], pads=[1, 0, 0, 1, 0, 0], strides=[2, 1, 1], onnx_name=\"ConvTranspose_36\"](%onnx::ConvTranspose_118, %upsample2.0.weight, %upsample2.0.bias) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/modules/conv.py:1102:0\n",
      "  %input.104 : Float(1, 64, 32, 7, 7, strides=[100352, 1568, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002, onnx_name=\"BatchNormalization_37\"](%input.100, %upsample2.1.weight, %upsample2.1.bias, %upsample2.1.running_mean, %upsample2.1.running_var) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:2438:0\n",
      "  %input.108 : Float(1, 64, 32, 7, 7, strides=[100352, 1568, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Elu[alpha=1., onnx_name=\"Elu_38\"](%input.104) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1549:0\n",
      "  %x.3 : Float(1, 64, 32, 1, 1, strides=[2048, 32, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::AveragePool[kernel_shape=[1, 7, 7], strides=[1, 7, 7], onnx_name=\"AveragePool_39\"](%input.108) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1231:0\n",
      "  %input.112 : Float(1, 64, 32, 1, 1, strides=[2048, 32, 1, 1, 1], requires_grad=1, device=cuda:0), %124 : Tensor = onnx::Dropout[ratio=0.5, onnx_name=\"Dropout_40\"](%x.3) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/functional.py:1252:0\n",
      "  %onnx::Reshape_125 : Float(1, 1, 32, 1, 1, strides=[32, 32, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[1, 1, 1], pads=[0, 0, 0, 0, 0, 0], strides=[1, 1, 1], onnx_name=\"Conv_41\"](%input.112, %ConvBlock10.weight, %ConvBlock10.bias) # /home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/nn/modules/conv.py:602:0\n",
      "  %130 : Float(1, 32, strides=[32, 1], requires_grad=1, device=cuda:0) = onnx::Reshape[onnx_name=\"Reshape_42\"](%onnx::Reshape_125, %onnx::Reshape_134) # /home/d/Projects/stress/models/physnet.py:125:0\n",
      "  %131 : Float(1, 3, 32, 120, 120, strides=[1382400, 460800, 14400, 120, 1], requires_grad=0, device=cuda:0) = onnx::Identity[onnx_name=\"Identity_43\"](%input.1)\n",
      "  return (%130, %131, %onnx::Reshape_125, %onnx::MaxPool_104)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py:1135: UserWarning: ONNX export mode is set to inference mode, but operator dropout is set to training  mode. The operators will be exported in training , as specified by the functional operator.\n",
      "  warnings.warn(\n",
      "/home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:2384: UserWarning: Dropout is a training op and should not be exported in inference mode. For inference, make sure to call eval() on the model and to export it with param training=False.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.cuda.FloatTensor(1, 3, 32, 120, 120)\n",
    "torch.onnx.export(model.module, dummy_input, f='pulse.onnx', training=False, verbose=True, \n",
    "                  opset_version=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c69c0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54859116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936df91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "413d0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEBUG Uncaught \n",
    "# (in promise) TypeError: cannot resolve operator 'ConvTranspose' with opsets: ai.onnx v9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4aa1828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "model2 = onnx.load('pulse.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83b19f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.checker.check_model(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0ac6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save_model(model2, 'pulse2.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56362c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aten::adaptive_avg_pool3d'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/miniconda3/envs/ONNX/lib/python3.8/site-packages/torch/onnx/symbolic_opset12.py:57: UserWarning: Dropout is a training op and should not be exported in inference mode. For inference, make sure to call eval() on the model and to export it with param training=False.\n",
      "  warnings.warn(\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of aten::adaptive_avg_pool3d type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of aten::adaptive_avg_pool3d type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    }
   ],
   "source": [
    "from torch.onnx import utils as onnx_utils\n",
    "\n",
    "torch_script_graph, unconvertible_ops = onnx_utils.unconvertible_ops(\n",
    "    model, dummy_input, opset_version=16)\n",
    "\n",
    "print(set(unconvertible_ops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29029d53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
